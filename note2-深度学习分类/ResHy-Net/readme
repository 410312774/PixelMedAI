We constructed a hybrid deep learning model, ResHy-Net, by combining ResNet18 and Transformer. ResNet18, with its last layer and classification layer removed, served as the feature extractor. It extracted CT features from the intra-abdominal fat, subcutaneous abdominal fat, and abdominal skeletal muscle regions, respectively, and these features were concatenated along the channel dimension. Subsequently, the concatenated features were divided into fixed-size blocks and fed into a multi-head self-attention module for modeling, obtaining block representations that incorporate positional information. Finally, a multi-layer perceptron classifier was used to decode and predict survival outcomes.
